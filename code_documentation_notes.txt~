Parameters for running the code:

	   Radius of influence: The radius of influence should default to 45 km, as this was shown to provide good 
	   approximation results. However, when testing the code it is often useful to decrease the radius to about 
	   15 km as this will speed up the code significantly. 

	   Correlation Model: The correlation model is set using a string, i.e., 'JB2009' for Jayaram and Baker 2009. 
	   Currently this is the only correlation model included here because it is the only correlation model 
	   implemented in the GEM openquake software package. Once others are implemented string key words can be 
	   added in the loop.py script function main to set the class CM. 



Set up of the inputs directory:

        Currently, the inputs directory needs 3 input files: grid, stationlist, and uncertainty xml files

	In the case where multiple ShakeMaps (on the same grid) are to be used, the grid, stationlist, and uncertainty xml files 
	should be in a numbered file. For example, when 3 ShakeMaps are used, the input directory should look like this:

	1  2   grid.xml	  stationlist.xml uncertainty.xml

	where 1 and 2 are directories containing grid, stationlist, and uncertainty xml files.



Uncertainty:

	Currently, the two forms of uncertainty used are the GMPE outputted intra and inter event uncertainty terms. 
	The actualy uncertainty that is applied to the random field is dependent on whether the bias is computed within the ShakeMap grid. 
	The function to determine whether the bias is computed is ComputeBias in the setup.py script. 

	if bias is computed: uncertainty = GMPE intraevent uncertainty
	if bias is not computed: uncertainty = sqrt((r*GMPE_inter)^2 + GMPE_intra^2), where r is a standard normal random variable.

	When directivity is used in the ShakeMap, this will change the uncertainty generated by the ShakeMap (stdpga, stdpgv, ...) but 
	will not change the GMPE uncertainty values. Therefore the reduction is sigma is not currently being applied to the spatial
	variability term added to the ShakeMap.


Current Parallelization Method:
	
	Using mpi4py, the fastest method for sending data is to use numpy arrays. Data structures like lists may be sent using mpi4py functions, 
	however they are pickled and unpickled which causes the whole process to slow down. This code uses numpy arrays when possible, but this 
	does involve some manipulation to get the data into this form. 

	The three main pieces of data that need to be sent are the grid array, mu array, and sigma array. 
	We are using the conditional multivariate normal equation for each point on the grid:
	X = Sigma_21 * Sigma_11^-1 * x + R * y
	where Sigma_21, Sigma_11^-1, and R can be computed independently for each grid point and saved, y is a standard normal random variable, and
	x is the conditioning values. 
	
	The grid array contains the indicies of those points which are conditioned on (or the indicies of the values in x). This is initially stored
	as a list of arrays, as the array of indicies for each point varies in size.

	Mu array contains the values of Sigma_21 * Sigma_11^-1 for each grid point. This is stored as a list of arrays, since the size of this array 
	can change for each grid point. 

	Sigma array contains the values of R for each point. R is a 1x1 matrix, so Sigma array is stored as a numpy array.

	We would like to move the data in the grid and mu arrays into 1-D numpy arrays. We do this by counting the total number of terms in each list
	and preallocating arrays of those sizes. We also make another numpy array that has the sizes of each array in the list. For example, if we had

	grid_arr = [[1], [1,2], [1,2,3], [1,2,3,4], [2,3,4,5], [3,4,5,6]]
	
	we would create another array list_sizes_grid:
	
	list_sizes_grid = [1, 2, 3, 4, 4, 4]

	and allocate an array grid_vec to be the size 1 x sum(list_sizes_grid) or 1 x 18. Then we fill in grid_vec

	grid_vec = [1, 1, 2, 1, 2, 3, 1, 2, 3, 4, 2, 3, 4, 5, 3, 4, 5, 6]

	We send the list sizes grid to the master first so that it knows how much space to allocate for the vector grid_vec. 

	After each core has assembled its list_sizes_grid and grid_vec and sent these arrays to the master core, the master will reverse this process, 
	putting the data back into a list of arrays. The same process is used for the mu array.

	Keep in mind that each core has the data for each point in many rows, and the rows are not 
	consective. The master core figures out which data belongs in which row to fill the entire list.

	Once the master has the full grid, mu, and sigma arrays, it can broadcast these to the other cores for use in realizations. 

	
Data Output:

     The data is saved to file in the realizations.py script. The file type is hdf5. 
	


